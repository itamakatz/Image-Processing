#############################################################
# FILE: sol5.py
# WRITER: Liav Steinberg
# EXERCISE : Image Processing ex5
#############################################################

from skimage.color import rgb2gray
from scipy.misc import imread
# from keras import layers as klay, models as kmod
from keras.layers import Input, Convolution2D, Activation, merge
from keras.models import Model

from keras.optimizers import Adam
from scipy.ndimage import filters as flt
import sol5_utils as sut
import numpy as np

import matplotlib.pyplot as plt

#--------------------------helpers-----------------------------#


def read_image(filename, representation):
    # filename - file to open as image
    # representation - is it a B&W or color image
    im = imread(filename) / 255
    # check if it is a B&W image
    if(representation == 1):
        im = rgb2gray(im)
    # convert to float and normalize
    return (im).astype(np.float32)

def learn_X_model(quick_mode, load_func, corr_func, cs, nc, ne):
    """
    to reduce code repetition for section 7.2.1, 7.2.2
    """
    def corruption_func(im):
        """
        wrapper for the corruption function
        """
        return add_gaussian_noise(im, 0, 0.2) if corr_func == "gaussian_noise" \
            else random_motion_blur(im, [7])
    #######################################################
    images = load_func()
    batch_size = 100
    sam_per_epoch = 10000
    num_epochs = ne
    num_valid_sample = 1000
    if quick_mode:
        batch_size = 10
        sam_per_epoch = 30
        num_epochs = 2
        num_valid_sample = 30
    model = build_nn_model(cs, cs, nc)
    train_model(model, images, corruption_func, batch_size,
                sam_per_epoch, num_epochs, num_valid_sample)
    return model, nc

#--------------------------3-----------------------------#

def load_dataset(filenames, batch_size, corruption_func, crop_size):
    """
    Generator function for creating dataset of patches
    """
    images = {}
    while True:
        source, target = np.zeros((batch_size, 1, crop_size[0], crop_size[1]), np.float32), \
                         np.zeros((batch_size, 1, crop_size[0], crop_size[1]), np.float32)
        rand_files = np.random.choice(filenames, batch_size)
        for idx,_file_ in enumerate(rand_files):
            if _file_ not in images:
                images[_file_] = np.array(read_image(_file_, 1))
            image = images[_file_]
            corrupted_image = corruption_func(image)
            rand_X = np.random.randint(image.shape[0]-crop_size[0])
            rand_Y = np.random.randint(image.shape[1]-crop_size[1])
            source[idx,0,:,:] = corrupted_image[rand_X:rand_X + crop_size[0], rand_Y:rand_Y + crop_size[1]]
            target[idx,0,:,:] = image[rand_X:rand_X+crop_size[0], rand_Y:rand_Y+crop_size[1]]
        yield (source-0.5, target-0.5)

#--------------------------4-----------------------------#

conv_func = lambda channels, tensor: Convolution2D(channels, 3, 3, border_mode = "same")(tensor)

def resblock(input_tensor, num_channels):
    return merge([input_tensor,
                  conv_func(num_channels, Activation("relu")(conv_func(num_channels, input_tensor)))], mode = "sum")


def build_nn_model(height, width, num_channels):

    def applay_resblock(ReLu, iter_times):
        if iter_times: return ReLu
        return applay_resblock(resblock(ReLu, num_channels), iter_times - 1)

    input = Input(shape = (1, height, width))
    relu = Activation("relu")(conv_func(num_channels, input))
    output = conv_func(1, merge([relu, applay_resblock(relu, 5)], mode = "sum"))
    return Model(input, output)

def train_model(model, images, corruption_func, batch_size,
            samples_per_epoch, num_epochs, num_valid_sample):

    training_set = images[:int(len(images) * 0.8)]
    validation_set = images[int(len(images) * 0.8):]
    load_func = lambda set: load_dataset(set, batch_size, corruption_func, model.input_shape[2:])

    model.compile(loss = "mean_squared_error", optimizer = Adam(beta_2 = 0.9))
    model.fit_generator(load_func(training_set), samples_per_epoch=samples_per_epoch, nb_epoch=num_epochs,
                        validation_data = load_func(validation_set), nb_val_samples=num_valid_sample)

#--------------------------6-----------------------------#

def restore_image(corrupted_image, base_model, num_channels):

    new_model = build_nn_model(corrupted_image.shape[0], corrupted_image.shape[1], num_channels)
    new_model.set_weights(base_model.get_weights())
    prediction = new_model.predict(corrupted_image[np.newaxis, np.newaxis] - 0.5)[0] + 0.5
    return np.clip(prediction,0,1).reshape(corrupted_image.shape).astype(np.float32)

#--------------------------7.1.1-----------------------------#

def add_gaussian_noise(image, min_sigma, max_sigma):

    return np.clip(image + np.random.normal(scale = np.random.uniform(min_sigma, max_sigma), size = image.shape).astype(np.float32),
                   0, 1)

def learn_denoising_model(quick_mode = False):

    if quick_mode:
        batch_size = 10
        sam_per_epoch = 30
        num_epochs = 2
        num_valid_sample = 30
    else:
        batch_size = 100
        sam_per_epoch = 10000
        num_epochs = 5
        num_valid_sample = 1000

    model = build_nn_model(24, 24, 48)

    train_model(model, sut.images_for_denoising(),
                lambda im: add_gaussian_noise(im, 0, 0.2),
                batch_size, sam_per_epoch, num_epochs, num_valid_sample)

    return model, 48

def add_motion_blur(image, kernel_size, angle):

    return flt.convolve(image, sut.motion_blur_kernel(kernel_size, angle))

def random_motion_blur(image, list_of_kernel_sizes):

    return add_motion_blur(image, np.random.choice(list_of_kernel_sizes), np.random.uniform(high = np.pi))

def learn_deblurring_model(quick_mode = False):

    if quick_mode:
        batch_size = 10
        sam_per_epoch = 30
        num_epochs = 2
        num_valid_sample = 30
    else:
        batch_size = 100
        sam_per_epoch = 10000
        num_epochs = 10
        num_valid_sample = 1000

    model = build_nn_model(16, 16, 32)
    train_model(model, sut.images_for_deblurring(),
                lambda im: random_motion_blur(im, [7]),
                batch_size, sam_per_epoch, num_epochs, num_valid_sample)

    return model, 32

if __name__ == "__main__":

    test = 3
    if test == 1:
        im = read_image("train/2092.jpg", 1)
        noised_im = add_gaussian_noise(im, 0, 0.2)
        plt.imshow(noised_im, cmap=plt.cm.gray)
        plt.show()

    if test == 2:
        im = read_image("text_dataset/train/0000005_orig.png", 1)
        noised_im = random_motion_blur(im, [7])

        model, channels = learn_deblurring_model()
        restored = restore_image(noised_im, model, channels)
        fig = plt.figure()
        ax1 = fig.add_subplot(1, 2, 1, label="noise")
        ax1.title.set_text("noise")
        plt.imshow(noised_im, cmap=plt.cm.gray)
        ax2 = fig.add_subplot(1, 2, 2)
        ax2.title.set_text("restored")
        plt.imshow(restored, cmap=plt.cm.gray)
        plt.show()

    if test == 3:
        im = read_image("image_dataset/train/2092.jpg", 1)
        noised_im = add_motion_blur(im, 7, 0.2)

        model, channels = learn_denoising_model(True)
        restored = restore_image(noised_im, model, channels)

        fig = plt.figure()

        ax1 = fig.add_subplot(2, 2, 1, label="noise")
        ax1.title.set_text("noise")
        plt.imshow(noised_im, cmap=plt.cm.gray)

        ax2 = fig.add_subplot(2, 2, 2)
        ax2.title.set_text("restored")
        plt.imshow(restored, cmap=plt.cm.gray)

        ax3 = fig.add_subplot(2, 2, 3)
        ax3.title.set_text("Original")
        plt.imshow(im, cmap=plt.cm.gray)

        plt.show()